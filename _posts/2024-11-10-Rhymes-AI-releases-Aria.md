

**Rhymes AI drops Aria: small Multimodal MoE that beats GPT-4o and Gemini-1.5-Flash âš¡ï¸**

New player entered the game! Rhymes AI has just been announced, and unveiled Aria â€“ a multimodal powerhouse that's punching above its weight.

**Key insights:**

ğŸ§  Mixture-of-Experts architecture: 25.3B total params, but only 3.9B active.

ğŸŒˆ Multimodal: text/image/video â†’ text.

ğŸ“š Novel training approach: â€œmultimodal-nativeâ€ where multimodal training starts directly during pre-training, not just tacked on later

ğŸ“ Long 64K token context window

ğŸ”“ Apache 2.0 license, with weights, code, and demos all open

âš¡ï¸ On the benchmark side, Aria leaves some big names in the dust.

- It beats Pixtral 12B or Llama-3.2-12B on several vision benchmarks like MMMU or MathVista.
- It even overcomes the much bigger GPT-4o on long video tasks and even outshines Gemini 1.5 Flash when it comes to parsing lengthy documents.

But Rhymes AI isn't just showing off benchmarks. They've already got Aria powering a real-world augmented search app called â€œBeagoâ€. Itâ€™s handling even recent events with great accuracy!

And they partnered with AMD to make it much faster than competitors like Perplexity or Gemini search.

Read their paper for Aria ğŸ‘‰Â [https://huggingface.co/papers/2410.05993](https://huggingface.co/papers/2410.05993)

Try BeaGo ğŸ¶ [ğŸ‘‰Â https://rhymes.ai/blog-details/meet-rhymes-ai-powerful-ai-built-for-all](https://rhymes.ai/blog-details/introducing-beago-your-smarter-faster-ai-search)

{% include image.html url="/assets/images/2024-11-10-Rhymes-AI-releases-Aria/image.png" description="image.png" %}
---
title: "What is 0.5!?"
last_modified_at: 2019-11-22 9:50:00 +0000
categories:
  - study
tags:
  - math
---

In a [previous post], we looked at the Poisson distribution as a way of modeling the probability of some event's occurrence within a specified time frame. Specifically, we took the example of phone calls and calculated how lucky I was on the day I got only five calls during my shift, as opposed to the typical twelve. 

While we clearly established the fact that the Poisson distribution was a more accurate representation of the situation than the binomial distribution, we ran into a problem at the end of the post: how can we derive or integrate the Poisson probability distribution, which is discontinuous? To recap, let's reexamine the Poisson distribution function:

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

$$P(X = k) = \lim\limits_{n \to \infty} e^{- \lambda} \frac{\lambda^k}{k!}$$

As you can see, this function is discontinuous because of that one factorial term shamelessly flaunting itself in the denominator. The factorial, we might recall, is as an operation is only defined for integers. Therefore, although we can calculate expression such as $$7!$$, we have no idea what the expression $$0.5!$$ evaluates to. 

Or do we?

Here is where the Gamma function kicks in. This is going to be the crux of today's post. 

# The Gamma Function

Let's jump right into it by analyzing the [Gamma function], specifically Euler's integral of the second kind:

$$\Gamma(n + 1) = \int_0^\infty x^n e^{-x} \, dx$$

At a glance, it is not immediately clear as to why this integral is an [interpolation] of the factorial function. However, if we try to evaluate this expression through integration by parts, the picture becomes clearer:

$$\int_0^\infty x^n e^{-x} \, dx = - x^n e^{-x} \Big|_{0}^{\infty} + n \int_0^\infty x^{n - 1} e^{-x} \, dx$$

Notice that the first term evaluates to 0. Moreover, the integral term can be expressed in terms of the Gamma function since

$$\int_0^\infty x^{n - 1} e^{-x} \, dx = \Gamma(n - 1)$$

Applying all the simplifications leave us with

$$\Gamma(n + 1) = n\Gamma(n)$$

Notice that this is a recursive representation of the factorial, since we can further unravel $$\Gamma(n)$$ using the same definition. In other words, 

$$\Gamma(n + 1) = n \cdot (n - 1) \cdot (n - 2) \cdot \dots \cdot 1 = n!$$

So it is now clear that the Gamma function is indeed an interpolation of the factorial function. But the Gamma function deserves a bit more attention and analysis than the simple evaluation we have performed above. Specifically, I want to introduce a few more alternative forms of expressing and deriving the Gamma function. There are many ways to approach this subject, and it would be impossible to exhaust through the entire list of possible representations. For the purposes of this post, we look at two forms of the Gamma function I find intriguing. 

The first version, presented below, is Euler's definition of the Gamma function as an infinite product. 

$$\Gamma(x) = \lim\limits_{n \to \infty} \frac{n^x n!}{x(x + 1)(x + 2) \dots (x + n)}$$

To see how this comes from, we backtrack this equality by dividing the right-hand side by $$(x - 1)!$$. 

$$\lim\limits_{n \to \infty} \frac{n^x n!}{x(x + 1)(x + 2) \dots (x + n) \cdot (x - 1)!} = \lim\limits_{n \to \infty} \frac{n^x n!}{(x + n)!} = 1$$

At this point, we can reduce the fraction by eliminating $$n!$$ from both the denominator and the numerator, which leaves us with the following expression:

$$\lim\limits_{n \to \infty} \frac{n^x}{(n + 1)(n + 2) \dots (n + x)} = \lim\limits_{n \to \infty} \frac{n}{(n + 1)} \frac{n}{(n + 2)} \dots \frac{n}{(n + x)} = 1$$

Therefore, we have

$$(x - 1)! = \Gamma(x) = \lim\limits_{n \to \infty} \frac{n^x n!}{x(x + 1)(x + 2) \dots (x + n)}$$

This is another representation of the Gamma function that is distinct from the integral we saw earlier. The last form that we will see involves some tweaking of the [harmonic series], or the simplest case of the Riemann zeta function where $$s = 1$$. We start from $$\log x!$$. 

$$f(x) = \ln x! = \ln x + \ln (x - 1)! = \ln x + f(x - 1)$$

We derive both sides by $$dx$$ to obtain the following:

$$f'(x) = \frac{1}{x} + f'(x - 1) = \frac{1}{x} + \frac{1}{x - 1} \dots \frac{1}{1} + f'(0)$$

Notice the harmonic series embedded in the expression above. To further simplify this expression, we derive an interpolation of the harmonic series. Let the interpolation be denoted as $$g(n)$$:

$$g(n) = t + \frac{1}{2}t^2 + \dots + \frac{1}{n}t^n$$

We derive both sides by $$n$$ to obtain the following:

$$g'(n) = 1 + t + \dots + t^{n - 1}$$

The expression above is the sum of a geometric series with radius $$t$$. 

$$g'(n) = \frac{1 - t^n}{1 - t}$$

We integrate both sides by $$n$$ to obtain $$g(n)$$. 

$$\int g'(n) \, dn = g(n) = \int \frac{1 - t^n}{1 - t} \, dn$$

We are almost done! Now that we have the expression for the harmonic series, we can plug it back into the original equation on $$f(x)$$ to finish off this derivation. 

$$f'(x) = \frac{1}{x} + \frac{1}{x - 1} + \dots + \frac{1}{1} + f'(0) = \int_0^1 \frac{1 - t^n}{1 - t} + f'(0) \, dn$$

Integrate both sides by $$x$$ to obtain the following:

$$f(x) = \ln x! = \int_0^x \int_0^1 \frac{1 - t^n}{1 - t} + f'(0) \, dn \, dx$$

Exponentiate both sides by $$e$$ to remove the logarithm, and we finally get the alternative representation of the Gamma function:

$$e^{\ln x!} = x! = \Gamma(x - 1) = e^{\int_0^x \int_0^1 \frac{1 - t^n}{1 - t} + f'(0) \, dn \, dx}$$ 

So we see that there are many other alternate modes of expressing the same function, $$\Gamma(n)$$. But the truth that remains unchanged is that the Gamma function is essentially a more expansive definition of the factorial that allows for operations on any real numbers. There are many concepts and theories surrounding the Gamma function, such as the [Euler-Mascheroni constant], [Mellin transformation], and countless many more, but these might be tabled for another discussion as they each deserve a separate post.

# The Gamma Distribution

The Gamma distribution is, just like the [binomial] and [Poisson distribution] we saw earlier, ways of modeling the distribution of some random variable $$X$$. Deriving the probability density function of the Gamma distribution is fairly simple. We start with two parameters, $$\alpha > 0$$ and $$\beta > 0$$, using which we can construct a Gamma function. 

$$\Gamma(\alpha) = \int_0^\infty x^{\alpha - 1} e^{-x} \, dx$$

We can divide both sides by $$\Gamma(\alpha)$$ to obtain the following expression:

$$1 = \frac{\int_0^\infty x^{\alpha - 1} e^{-x} \, dx$$}{\Gamma(\alpha)}$$

We can then apply the substitution $$x = \beta y$$ to obtain

$$1 = \frac{\int_0^\infty \beta^\alpha y^{\alpha - 1} e^{-\beta y} \, dy$$}{\Gamma(\alpha)}$$

Notice that we can consider the integrand to be a probability distribution function since the result of integration over the prescribed domain yields 1, the total probability. Seen this way, we can finally delineate a definition of the Gamma distribution as follows, with a trivial substitution of parameters.

$$P(T = k; \alpha, \beta) = \frac{\beta^\alpha k^{\alpha - 1} e^{-\beta k} \, dk$$}{\Gamma(\alpha)}$$

If this derivation process does not click with you, we can take the alternative route of starting from the functional definition of the Gamma distribution: the Gamma distribution models the waiting time until the occurrence of the $$k$$th event in a [Poisson] process. In other words, given some rate $$\lambda$$ which denotes the rate at which an event occurs, what is the distribution of the waiting time going to look like? The Gamma distribution holds an answer to this question.

Let’s jump right into derivation. The first ingredient we need is the equation for the Poisson probability distribution function, which we might recall goes as follows:

$$P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}$$

The link between the Poisson and Gamma distributions is established by the fact that the waiting time $$w$$ for $$k$$ events is equal to the probability that $$(k - 1)$$ events, with a rate of occurrence $$\lambda w$$, happen within $$w$$, where we consider $$w$$ to be unit time. Using this idea, we can construct the [cumulative probability distribution function] of the Gamma distribution as follows:

$$F(w) = P(W \leq w) = 1 - P(W > w) = 1 - \sum_{i = 0}^{k - 1} \frac{{\lambda w}^k e^{-\lambda w}}{k!}$$

Note that this expression is coherent.







[interpolation]: https://en.wikipedia.org/wiki/Interpolation

[Gamma function]: https://en.wikipedia.org/wiki/Gamma_function

[harmonic series]: https://en.wikipedia.org/wiki/Harmonic_series_(mathematics)

[Riemann zeta function]: https://en.wikipedia.org/wiki/Riemann_zeta_function

[previous post]: https://jaketae.github.io/study/poisson/

[binomial]: https://en.wikipedia.org/wiki/Binomial_distribution

[Poisson distribution]: https://en.wikipedia.org/wiki/Poisson_distribution

[Euler-Mascheroni constant]: https://en.wikipedia.org/wiki/Euler–Mascheroni_constant

[Mellin transformation]: https://en.wikipedia.org/wiki/Mellin_transform

[Poisson]: https://en.wikipedia.org/wiki/Poisson_distribution

[cumulative probability distribution function]: https://en.wikipedia.org/wiki/Cumulative_distribution_function



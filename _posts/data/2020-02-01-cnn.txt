recently, a friend recommended me a book, deep learning with python by francois chollet. as an eager learner just starting to fiddle with the keras api, i decided it was a good starting point. i have just finished the first section of part 2 on convolutional neural networks and image processing. my impression so far is that the book is more focused on code than math. the apparent advantage of this approach is that it shows readers how to build neural networks very transparently. it's also a good introduction to many neural network models, such as cnns or lstms. on the flip side, it might leave some readers wondering why these models work, concretely and mathematically. this point notwithstanding, i've been enjoying the book very much so far, and this post is a reflection of just that. today, we will use tensorflow's module to build a convolutional neural network for image detection. this code is based on what i have learned from the book, so much credit goes to deep learning with python. i have also looked at machine learning mastery blog for additional reference. let's begin! below are the modules that we will need to import for this demonstration. note that this jupyter notebook was written on google colaboratory. the default version of tensorflow in colab will soon switch to tensorflow 2.x. we recommend you upgrade now or ensure your notebook will continue to use tensorflow 1.x via the %tensorflow_version 1.x magic: more info. the function loads the cifar10 data set from module, then applies some basic preprocessing to make it more usable for deep learning purposes. the cifar10 data set contains 50000 training images, each labeled with 1 of 10 classes, ranging from cats, horses, and trucks to airplanes. this is a classic classification task. the preprocessing occurs on two levels: first, the images are normalized so that its pixels takes values between 0 and 1. the training labels are transformed from an integer class label to a one hot encoded vector. let's load the data to proceed with our analysis. let's see what the dimensions of the data are. because the cifar10 data set include color images for its training set, we would expect three channels, each corresponding to red, green, and blue . as expected, it appears that the training data is a tensor of four dimensions, while the target labels are 10 dimensional vectors. to get a better idea of what the cifar10 data looks like, here is a basic function that will display the images in the data set for us using . we can see that, although the images are very pixelated, it is somewhat possible to make out what each image is showing. of course, this task is going to be a lot more difficult for our neural network. now is finally the time to buid the neural network. this network pretty much follows the standard vanilla convolutional neural network model, which typically involves stacking convolution, batch normalization, and pooling layers on top of each other. the dropout layers were also added so as to minimize any potential overfitting. the argument was configured as , named after kaiming he who found the optimal weight initialization kernel for convolutional layers. the argument ensures that the the feature maps are not downsized too quickly due to repeated applications of convolution and pooling. the layer simply normalizes the tensor returned from the previous layer. there are ongoing research as to what effect batch normalization has on neural networks, but the general consensus is that it helps the model learn more quickly and efficiently. the function returns the predefined sequential model, compiled using the configurations as shown below. let's take a look at the summary of the model. the summary shows that this model has 551,466 trainable parameters. the memory capacity of this model is not big, but it is definitely larger than the network we built in the previous post using the keras api. warning:tensorflow:from /usr/local/lib/python3.6/dist packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling baseresourcevariable.__init__ with constraint is deprecated and will be removed in a future version. instructions for updating: if using keras pass _constraint arguments to layers. model: "sequential" _________________________________________________________________ ================================================================= conv2d 896 _________________________________________________________________ batch_normalization 128 _________________________________________________________________ conv2d_1 9248 _________________________________________________________________ batch_normalization_1 128 _________________________________________________________________ max_pooling2d 0 _________________________________________________________________ dropout 0 _________________________________________________________________ conv2d_2 18496 _________________________________________________________________ batch_normalization_2 256 _________________________________________________________________ conv2d_3 36928 _________________________________________________________________ batch_normalization_3 256 _________________________________________________________________ max_pooling2d_1 0 _________________________________________________________________ dropout_1 0 _________________________________________________________________ conv2d_4 73856 _________________________________________________________________ batch_normalization_4 512 _________________________________________________________________ conv2d_5 147584 _________________________________________________________________ batch_normalization_5 512 _________________________________________________________________ max_pooling2d_2 0 _________________________________________________________________ dropout_2 0 _________________________________________________________________ flatten 0 _________________________________________________________________ dense 262272 _________________________________________________________________ dropout_3 0 _________________________________________________________________ dense_1 1290 ================================================================= total params: 552,362 trainable params: 551,466 non trainable params: 896 _________________________________________________________________ now that the model is ready to be deployed, we need to train and test the model. but before that, let's quickly define a function that will provide us with a visualization of how the model is learning. this function is very similar to the one used in the previous post all it does it that it plots the model's accuracy and cross entropy loss with each epoch. this visualization will help us see whether our model is actually learning with each epoch, and whether or not overfitting is occurring at any point in training. the last piece of the puzzle we need is the function. this function is essentially wraps all the functions we have created previously, first by loading the data, training using that data, building a model, training a model, and calling on the function to provide a visualization of the model's learning curve. one minor tweak i used to spice up this function is the , which basically creates more images for the neural network to train on by slightly modifying existing images in the training set. these modifications involve shifting, zooming, and flipping. when we don't have enough data to train our model on, using the can be useful. finally, let's see how well our model performs! epoch 1/50 epoch 1/50 5000/704 1s loss: 1.4018 acc: 0.4452 704/704 24s loss: 1.9197 acc: 0.3393 val_loss: 1.5981 val_acc: 0.4452 epoch 2/50 epoch 1/50 5000/704 1s loss: 1.3273 acc: 0.5178 704/704 22s loss: 1.4458 acc: 0.4765 val_loss: 1.4521 val_acc: 0.5178 epoch 3/50 epoch 1/50 5000/704 1s loss: 0.9988 acc: 0.5868 704/704 22s loss: 1.2782 acc: 0.5444 val_loss: 1.1961 val_acc: 0.5868 epoch 4/50 epoch 1/50 5000/704 1s loss: 1.2566 acc: 0.5264 704/704 21s loss: 1.1569 acc: 0.5904 val_loss: 1.5175 val_acc: 0.5264 epoch 5/50 epoch 1/50 5000/704 1s loss: 1.0085 acc: 0.6482 704/704 22s loss: 1.0686 acc: 0.6256 val_loss: 1.0519 val_acc: 0.6482 epoch 6/50 epoch 1/50 5000/704 1s loss: 0.9098 acc: 0.6940 704/704 22s loss: 0.9966 acc: 0.6506 val_loss: 0.8696 val_acc: 0.6940 epoch 7/50 epoch 1/50 5000/704 1s loss: 1.0636 acc: 0.6506 704/704 22s loss: 0.9380 acc: 0.6744 val_loss: 1.0681 val_acc: 0.6506 epoch 8/50 epoch 1/50 5000/704 1s loss: 0.8172 acc: 0.7074 704/704 22s loss: 0.9034 acc: 0.6847 val_loss: 0.8733 val_acc: 0.7074 epoch 9/50 epoch 1/50 5000/704 1s loss: 0.6724 acc: 0.7406 704/704 22s loss: 0.8547 acc: 0.7062 val_loss: 0.7682 val_acc: 0.7406 epoch 10/50 epoch 1/50 5000/704 1s loss: 0.7381 acc: 0.7498 704/704 22s loss: 0.8273 acc: 0.7144 val_loss: 0.7370 val_acc: 0.7498 epoch 11/50 epoch 1/50 5000/704 1s loss: 0.8509 acc: 0.7356 704/704 22s loss: 0.7928 acc: 0.7277 val_loss: 0.7625 val_acc: 0.7356 epoch 12/50 epoch 1/50 5000/704 1s loss: 0.5065 acc: 0.8012 704/704 22s loss: 0.7791 acc: 0.7338 val_loss: 0.5763 val_acc: 0.8012 epoch 13/50 epoch 1/50 5000/704 1s loss: 0.6216 acc: 0.7698 704/704 22s loss: 0.7530 acc: 0.7410 val_loss: 0.7289 val_acc: 0.7698 epoch 14/50 epoch 1/50 5000/704 1s loss: 0.5690 acc: 0.7570 704/704 22s loss: 0.7303 acc: 0.7490 val_loss: 0.6940 val_acc: 0.7570 epoch 15/50 epoch 1/50 5000/704 1s loss: 0.4754 acc: 0.7940 704/704 22s loss: 0.7092 acc: 0.7604 val_loss: 0.6025 val_acc: 0.7940 epoch 16/50 epoch 1/50 5000/704 1s loss: 0.7061 acc: 0.7704 704/704 22s loss: 0.6983 acc: 0.7622 val_loss: 0.6904 val_acc: 0.7704 epoch 17/50 epoch 1/50 5000/704 1s loss: 0.4567 acc: 0.8052 704/704 21s loss: 0.6852 acc: 0.7658 val_loss: 0.5671 val_acc: 0.8052 epoch 18/50 epoch 1/50 5000/704 1s loss: 0.3820 acc: 0.8304 704/704 21s loss: 0.6692 acc: 0.7736 val_loss: 0.4989 val_acc: 0.8304 epoch 19/50 epoch 1/50 5000/704 1s loss: 0.5878 acc: 0.7718 704/704 22s loss: 0.6491 acc: 0.7782 val_loss: 0.6974 val_acc: 0.7718 epoch 20/50 epoch 1/50 5000/704 1s loss: 0.4602 acc: 0.7876 704/704 22s loss: 0.6468 acc: 0.7807 val_loss: 0.6501 val_acc: 0.7876 epoch 21/50 epoch 1/50 5000/704 1s loss: 0.4576 acc: 0.8152 704/704 21s loss: 0.6296 acc: 0.7876 val_loss: 0.5577 val_acc: 0.8152 epoch 22/50 epoch 1/50 5000/704 1s loss: 0.4969 acc: 0.8178 704/704 21s loss: 0.6297 acc: 0.7870 val_loss: 0.5341 val_acc: 0.8178 epoch 23/50 epoch 1/50 5000/704 1s loss: 0.4315 acc: 0.7962 704/704 21s loss: 0.6142 acc: 0.7916 val_loss: 0.5970 val_acc: 0.7962 accuracy: 78.76999974250793% the result shows that the model has learned decently well, with testing accuracy of approximately 80 percent. this is not the best result, but it is certainly not bad, especially given the fact that the images in the dataset, as we have seen above, are very pixelated and sometimes difficult for even humans to decipher and categorize. that's all for today. it's fascinating to see how cnns are capable of perceiving images and categorizing them after appropriate training. but as we all know, the potential of neural networks far extends beyond image classificaiton. in a future post, we might look at more complicated models, such as rnn or lstms, to achieve even cooler tasks! deep learning with python: https://www.manning.com/books/deep learning with python machine learning mastery blog: https://machinelearningmastery.com/how to develop a cnn from scratch for cifar 10 photo classification/ previous post: https://jaketae.github.io/study/first keras/
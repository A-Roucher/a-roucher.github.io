recently, i was compelled by my own curiosity to study sql, a language i have heard about quite a lot but never had a chance to study. at first, sql sounded difficult and foreign largely because it was a language fundamentally different from other programming languages i had studied, such as java, python, or r. however, after watching this fantastic video tutorial on youtube, and completing a relevant course on datacamp, i think i now finally have a somewhat concrete understanding of what sql is and how to use it. of course, i'm still so far away from being fluent in sql, and the queries i can write are still pretty basic. much like the blog post on r, this post will serve as a reference for myself. note: this notebook was drafted in january of 2020, yet i never had a chance to finish it. finally, while working on some r tutorial notebooks on the package, i was reminded of this draft and hence decided to publish it. hopefully this editorial discontinuity does not affect the quality of writing and content of this article. there are many different ways of using and accessing sql from jupyter notebooks. here, i introduce two simple ways of practicing sql without much complicated setup. the first on the list is , which allows us to use magic commands in jupyter notebooks. to install, simply type the following line in the terminal, assuming that you have activated the conda virtual environment of choice. we can now use the magic command in jupyter to connect to a local database. in my case i had a mysql database initialized at localhost, and was able to connect to it as a root user. note that you should replace in the example command below according to your own configuration. 'connected: root@test' now that we have successfully connected to the data, we can use sql commands in jupyter! mysql+pymysql://root:@localhost:3306/test 5 rows affected. emp_id first_name last_name birth_day sex salary super_id branch_id 103 angela martin 1971 06 25 f 63000 102 2 101 jan levinson 1961 05 11 f 110000 100 1 104 kelly kapoor 1980 02 05 f 55000 102 2 107 andy bernard 1973 07 22 m 65000 106 3 100 david wallace 1967 11 17 m 250000 none 1 this method works, but it requires that you set up a mysql server on your local workstation. while this is not particularly difficult, this method is somewhat made less compelling by the fact that it does not work right out of the box. the method i prefer, therefore, is the one that i would like to introduce next. is an incredibly widely used python module for deailng with tabular data. it some similarities with sql in that they both deal with tables at the highest level. of course, the two serve very different purposes: sql is intended as a backend exclusive language, powering huge database servers and allowing developers to quickly query through large amounts of data. , on the other hand, is a must have in the python data scientist's toolbox, allowing them to extract new insight from organized tabular data. is a python module that allows us to query s using sql syntax. in other words, it is a great way to learn sql. the benefit of this approach is that no database setup is necessary: as long as there is some tabular data to work with, say some file, we are ready to go. for the purposes of this post, we will thus be using this latter approach. with all that said, let's get started. in this section, we will go over some basic core sql statements to get our feet wet. it would be utterly impossible for me to cover sql syntax in any level of detail in a single blog post, but this is a start nonetheless. at the minimum, i hope to continue this series as i start learning more sql. the main references used to write this post were this excellent medium article and the official documentation on the website. let's begin by loading a library to import some sample toy datasets at our disposal. let's first see a simple example of in action, alongwith . one of the perks of sql is that it somewhat reads like plain english instead of complicated computer code. of course, sql statements can get quite complex, in which case this rule starts to break down. however, it isn't too difficult to see what the statement above is doing: it is selecting the column and from the dataset which we loaded, and showing the top five results only in accordance with the . we can also replicate the output of by doing the following. the is essentially a wild card argument that tells sql that we want information pulled from every column instead of a specified few. this can be handy when we want to take a glimpse of the contents of the database. is not the only addition we can make to a statement. for instance, consider the keyword , which does exactly what you think it does: as you can see, allows us to select only unique values in the table. note that offers a simliar function, , with which we can somewhat recreate a similar result. array another useful fact to remember is that most often goes along with . we can imagine many instances where we would want to retrieve only those data entries that satisfy a certain condition. in the example below, we retrieve only those data entries whose species are labeled as . in speak, we would have done the following: 0 1.4 1 1.4 2 1.3 3 1.5 4 1.4 name: petal_length, dtype: float64 the version is not too difficult just yet, buti prefer sql's resemblance to plain human language. just for the sake of it, let's take a look at a slightly more complicated conditioning we can perform with , namely by linking multiple conditions on top of each other. in this example, we select and for only those entries whose species is setosa and is smaller than 3.2 . all we did there was join the two conditions via the keyword. in , this is made slighty more confusing by the fact that we use slicing to make multi column selections. and by the same token, the sql keyword translates into in . instead of sticking in the end, we could have used as we have been doing so far. it isn't difficult to see that introducing more conditionals can easily result in somewhat more longer statements in python, whereas that is not necessarily the case with sql. this is not to say that is inferior or poorly optimized; instead, it simply goes to show that the two platforms have their own comaprative advantages and that they mainly serve different purposes. often time when sorting through some tabular data, we want to sort the entries in ascending or descending order according to some axis. for example, we might want to rearrange the entries so that one with the largest comes first. let's see how we can achieve this with sql. by default, the keyword in sql lists values in asending order. to reverse this, we can explicitly add the keyword. we see that the entries with the largets is indeed at the top of the selected query result. we can also achieve a similar result in . in this case, i think also offers a simple, clean interface to access data. one point to note is that both sql and have the same default settings when it comes to ordering or sorting entries: by default, . also, it is interesting to see that sql does not have references to row values or ids because we did not set them up, whereas automatically keeps track of the original location of each row and displays them in the queried result. i decided to jam pack this last section with a bunch of somewhat similar commands: namely, , , and . these commands are loosely related to each other, which is why they are all grouped under this section. speaking of groups, we will continue our discussion of sql and in another post, starting with things lilke and . anyhow, let's begin by taking a look at . in sql, we can make selections based on whether an entry falls into a certain category. for instance, we might want to select data points only for setosas and virginicas. in that case, we might use the following sql statement. to demonstrate the fact that we have both setosas and virginicas, i decided to avoid the use of . the resulting table is has 100 rows and five columns. let's see if we can replicate this result in using . as expected, we also get a 100 by 5 table containing only setosas and virginicas. it is worth noting that this was not the smartest way to go about the problem; we could have used negative boolean indexing: namely, we could have told to pull every data point but those pertaining to versicolors. for example, in development settings, we would of course use the negative boolean indexing approach shown immediately above, but for demonstration purposes, it helps to see how can be used to model . in sql, empty values are encoded as . we can perform selection based on whether or not there is a entry in a row. this functionality is particularly important to preprocess data, which might be fed into some machine learning model. first, observe that the current data does not have any values. 0 therefore, let's add two dummy rows for the purposes of this demonstration. there are many ways to go about adding a row. for example, we might want to assign a new row by saying , or use . let's try the first approach for simplicity. now that we have this dummy row, let's see what we can do with sql. in fact, the syntax is not so much different from what we've been doing so far. the only new part is , which specifies that a certain attribute or column is . again, this is one of those instances that show that sql statements somewhat read like normal english statements. , on the other hand, obviously doesn't flow as easily, but its syntax is not so much complicated either: again, this shows that boolean indexing is a huge component of sifting through data frames. a lot of the inspiration behind this api obviously comes from r and treatment of its own data frames. the function does the exact opposite of . without running the function, we already know that substituting with will simply give us the rest of all the rows in the dataset. this post was intended as an introduction to sql, but somehow it digressed into a comparison of sql and syntax. nonetheless, for those who are already familiar with one framework, reading this cross comparison will help you glean a more intuitive sense of what the other side of the world looks like. as mentioned earlier, sql and each have their strenghts and weaknesses, and so it definitely helps to have both tools under the belt. as you might notice, my goal is to eventually gain some level of proficienchy in both python, sql, and r; hence the posts on r lately. it's interesting to see how different tools can be used to approach the same problem. better illuminated in that process are the philosophies behind each frameworks: where they each borrowed inspiration from, what values or ux aspects they prioritize, and et cetera. i hope you enjoyed reading this post. catch you up in the next one!
generative models are fascinating. it is no wonder that gans, or general adversarial networks, are considered by many to be where future lies for deep learning and neural networks. in this post, we will attempt to create a very simple vanilla gan using tensorflow. specifically, our goal will be to train a neural network that is capable of generating compelling images of ships. although this is a pretty mundane task, it nonetheless sheds lights on the potential that gan models hold. let's jump right into it. below are the dependencies and settings we will be using throughout this tutorial. before we start building the gan model, it is probably a good idea to define some variables that we will be using to configure the parameters of convolutional layers, namely the dimensionality of the images we will be dealing with, as well as the number of color channels and the size of the latent dimension. similar to variational autoencoders, gans are composed of two parts: the generator and the discriminator. as ian goodfellow described in the paper where he first put out the notion of a gan, generators are best understood as counterfeiters of currency, whereas the discriminator is the police trying to distinguish the fake from the true. in other words, a gan is a two component model that involves an internal tug of war between two adversarial parties, each trying their best to accomplish their mission. as this competition progresses, the generator becomes increasingly better at creating fake images; the discriminator also starts to excel at determining the veracity of a presented image. enough of theoretical dwellings, let's begin by defining the generator model. the is a function that returns a generator model according to some set parameters. let's take a look at the structure of this network in more detail. warning:tensorflow:from /usr/local/lib/python3.6/dist packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling baseresourcevariable.__init__ with constraint is deprecated and will be removed in a future version. instructions for updating: if using keras pass _constraint arguments to layers. model: "model" _________________________________________________________________ ================================================================= input_1 0 _________________________________________________________________ dense 4227072 _________________________________________________________________ leaky_re_lu 0 _________________________________________________________________ reshape 0 _________________________________________________________________ conv2d 819456 _________________________________________________________________ leaky_re_lu_1 0 _________________________________________________________________ conv2d_transpose 1048832 _________________________________________________________________ leaky_re_lu_2 0 _________________________________________________________________ conv2d_1 1638656 _________________________________________________________________ leaky_re_lu_3 0 _________________________________________________________________ conv2d_2 1638656 _________________________________________________________________ leaky_re_lu_4 0 _________________________________________________________________ conv2d_3 37635 ================================================================= total params: 9,410,307 trainable params: 9,410,307 non trainable params: 0 _________________________________________________________________ none notice that the output of the generator is a batch image of dimensions . this is exactly the same as the , , and information we defined earlier, and that is no coincidence: in order to fool the discriminator, the generator has to generate images that are of the same dimensions as the training images from imagenet. now it's time to complete the gan by creating a corresponding discriminator, the discerning police officer. the discriminator is essentially a simple binary classier that ascertains whether a given image is true or fake. therefore, it is no surprise that the final output layer will have one neuron with a sigmoid activation function. let's take a more detailed look at the function as shown below. and again, a model summary for convenient reference: warning:tensorflow:from /usr/local/lib/python3.6/dist packages/tensorflow_core/python/ops/nn_impl.py:183: where is deprecated and will be removed in a future version. instructions for updating: use tf.where in 2.0, which has the same broadcast rule as np.where model: "model_1" _________________________________________________________________ ================================================================= input_2 0 _________________________________________________________________ conv2d_4 3584 _________________________________________________________________ leaky_re_lu_5 0 _________________________________________________________________ conv2d_5 262272 _________________________________________________________________ leaky_re_lu_6 0 _________________________________________________________________ conv2d_6 262272 _________________________________________________________________ leaky_re_lu_7 0 _________________________________________________________________ conv2d_7 262272 _________________________________________________________________ leaky_re_lu_8 0 _________________________________________________________________ flatten 0 _________________________________________________________________ dropout 0 _________________________________________________________________ dense_1 513 ================================================================= total params: 790,913 trainable params: 790,913 non trainable params: 0 _________________________________________________________________ none now we have both the discriminator and the generator, but the two are not really connected in the sense that they exist as discrete models lacking any connection between them. what we want to do, however, is to establish some relationship between the generator and the discriminator to complete a gan, and hence train them in conjunction. this process of putting the pieces together, or adjoining the models, is where i personally find the genius in gan design. the key takeaway here is that we define and . as you might imagine, the shape of the input is defined by we defined earlier. this is the latent space from which we will sample a random noise vector frame to feed into our gan. then, the connection between the generator and the discriminator is effectively established by the statement . all this is saying is that gan's output is the evaluation of the generator's fake image by the discriminator. if the generator does well, it will fool the discriminator and thus output 1; 0 vice versa. let's take a look at the code implementation of this logic. model: "model_2" _________________________________________________________________ ================================================================= input_3 0 _________________________________________________________________ model 9410307 _________________________________________________________________ model_1 790913 ================================================================= total params: 10,201,220 trainable params: 9,410,307 non trainable params: 790,913 _________________________________________________________________ none now it's time to train our model. let's first load our dataset. for this, we will be using the images. the dataset contains low resolutions images, so our output is also going to be very rough, but it is a good starting point nonetheless. one hacky thing we do is concatenating the training and testing data. this is because for a gan, we don't need to differentiate the two: on the contrary, the more data we have for training, the better. one might suggest that testing data is necessary for the discriminator, which is a valid point, but the end goal here is to build a high performing generator, not the discriminator, so we will gloss over that point for now. for this tutorial, we will be using images of ships, which are labeled as 8. so let's go ahead and specify that. we see that contains 6000 images, which is more than enough to start training our gan. to train the gan, we will define a function. essentially, this function creates binary labels for real and fake images. recall that the goal of the discriminator is to successfully discern generated images from real ones. also recall that to create generated images, the generator needs to sample from a latent dimension. in other words, training will consist of the following steps: sample a random vector to be fed into the generator create zero labels for the corresponding generated images create one labels for real images from the training dataset train the discriminator with the two labels train the gan by coercing a true label for all images these high level abstractions are what implements behind the scenes. there are several subtleties that deserve our attention. first, we fade out the labels ever so slightly to expedite the training process. these are little magic tricks that people have found to work well on gan training. while i'm not entirely sure about the underlying principle, it most likely comes from the fact that having a smooth manifold is conducive to the training of a neural network. second, coercing a true label on the gan essentially trains the generator. note that we never explicitly address the generator in the function; instead, we only train the discriminator. by coercing a true label on the gan, we are effectively forcing the generator to produce more compelling images, and penalizing it when it fails to do so. personally, i find this part to be the genius and beauty of training gans. now that we have an idea of what the function accomplishes, let's use it to start training. warning:tensorflow:discrepancy between trainable weights and collected trainable weights, did you set without calling after ? iteration 0/10000 ============================== d loss: 0.679, gan loss: 0.736 iteration 200/10000 ============================== d loss: 0.560, gan loss: 2.285 iteration 400/10000 ============================== d loss: 0.678, gan loss: 0.801 iteration 600/10000 ============================== d loss: 0.556, gan loss: 2.400 iteration 800/10000 ============================== d loss: 0.695, gan loss: 0.705 iteration 1000/10000 ============================== d loss: 0.699, gan loss: 0.652 iteration 1200/10000 ============================== d loss: 0.718, gan loss: 0.606 iteration 1400/10000 ============================== d loss: 0.706, gan loss: 0.679 iteration 1600/10000 ============================== d loss: 0.675, gan loss: 0.702 iteration 1800/10000 ============================== d loss: 0.651, gan loss: 0.668 iteration 2000/10000 ============================== d loss: 0.748, gan loss: 0.805 iteration 2200/10000 ============================== d loss: 0.682, gan loss: 0.729 iteration 2400/10000 ============================== d loss: 0.402, gan loss: 3.102 iteration 2600/10000 ============================== d loss: 0.672, gan loss: 0.665 iteration 2800/10000 ============================== d loss: 0.659, gan loss: 0.534 iteration 3000/10000 ============================== d loss: 0.686, gan loss: 0.679 iteration 3200/10000 ============================== d loss: 0.645, gan loss: 0.679 iteration 3400/10000 ============================== d loss: 0.681, gan loss: 0.728 iteration 3600/10000 ============================== d loss: 0.792, gan loss: 1.180 iteration 3800/10000 ============================== d loss: 0.687, gan loss: 0.897 iteration 4000/10000 ============================== d loss: 0.791, gan loss: 1.159 iteration 4200/10000 ============================== d loss: 0.695, gan loss: 0.680 iteration 4400/10000 ============================== d loss: 0.671, gan loss: 0.706 iteration 4600/10000 ============================== d loss: 0.702, gan loss: 0.811 iteration 4800/10000 ============================== d loss: 0.697, gan loss: 0.634 iteration 5000/10000 ============================== d loss: 0.759, gan loss: 0.802 iteration 5200/10000 ============================== d loss: 0.677, gan loss: 0.740 iteration 5400/10000 ============================== d loss: 0.701, gan loss: 0.663 iteration 5600/10000 ============================== d loss: 0.670, gan loss: 0.598 iteration 5800/10000 ============================== d loss: 0.615, gan loss: 0.756 iteration 6000/10000 ============================== d loss: 0.677, gan loss: 0.626 iteration 6200/10000 ============================== d loss: 0.669, gan loss: 0.767 iteration 6400/10000 ============================== d loss: 0.682, gan loss: 0.644 iteration 6600/10000 ============================== d loss: 0.742, gan loss: 0.955 iteration 6800/10000 ============================== d loss: 0.701, gan loss: 0.680 iteration 7000/10000 ============================== d loss: 0.303, gan loss: 7.814 iteration 7200/10000 ============================== d loss: 0.596, gan loss: 0.847 iteration 7400/10000 ============================== d loss: 0.717, gan loss: 0.770 iteration 7600/10000 ============================== d loss: 0.707, gan loss: 0.742 iteration 7800/10000 ============================== d loss: 0.697, gan loss: 0.795 iteration 8000/10000 ============================== d loss: 0.647, gan loss: 0.672 iteration 8200/10000 ============================== d loss: 0.676, gan loss: 0.725 iteration 8400/10000 ============================== d loss: 0.608, gan loss: 1.050 iteration 8600/10000 ============================== d loss: 0.757, gan loss: 0.824 iteration 8800/10000 ============================== d loss: 0.614, gan loss: 0.758 iteration 9000/10000 ============================== d loss: 0.660, gan loss: 0.647 iteration 9200/10000 ============================== d loss: 0.651, gan loss: 1.122 iteration 9400/10000 ============================== d loss: 0.710, gan loss: 0.991 iteration 9600/10000 ============================== d loss: 0.734, gan loss: 0.901 iteration 9800/10000 ============================== d loss: 0.681, gan loss: 0.899 the seems to fluctuate a bit, which is not necessarily a good sign but also quite a common phenomenon in gan training. gans are notoriously difficult to train, since it requires balancing the performance of the generator and the discriminator in such a way that one does not overpower the other. this is referred to as a min max game in game theory terms, and finding an equilibrium in such structures are known to be difficult. let's take a look at the results now that the iterations are over. the created images are admittedly fuzzy, pixelated, and some even somewhat alien looking. this point notwithstanding, i find it incredibly fascinating to see that at least some generated images actually resemble ships in the sea. of particular interest to me are the red ships that appear in and . given the simplicity of the structure of our network, i would say that this is a successful result. let's take a look at the learning curve of the gan. as you might expect, the loss is very spiky and erratic. this is why it is hard to determine when to stop training a gan. of course, there are obvious signs of failure: when the loss of one component starts to get exponentially larger or smaller than its competitor, for instance. however, this did not happen here, so i let the training continue until the specified number of interactions were over. the results, as shown above, suggest that we haven't failed in our task. in a future post, we will be taking a look at the mathematics behind gans to really understand what's happening behind the scenes when we pit the generator against its mortal enemy, the discriminator. see you in the next post!
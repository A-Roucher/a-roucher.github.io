a few days ago, i saw a friend who posted an instagram story looking for partners to study r with. i jumped at the opportunity without hesitation—based on my experience these past six months, i knew all too well that studying alone is a lonely, difficult process. the hardest part about it is keeping oneself accountable and continuing a long streak without losing momentum. so i said that i’d love to join him and his crew. what we do as a group is nothing grandiose: we simply keep a log of what we’re studying and answer questions that others might have when they come up in our group chat. while the studying is mostly done on one’s own, the fact that we keep a semi public record of where we are in terms of our study should hopefully motivate all of us to keep making progress until the end. as for me, my goal is to finish the book r for data science, which i had meant to read but never went past chapter 1, mostly because i got carried away by other things. enough of the prologue, here’s a summary of what i’ve learned so far by from the book. introduction ============ is a powerful visualization package in r, much like in python. i’m not proficient enough in to make a direct comparison, but i’ve heard very positive things about eda with r, so i’m excited to learn and have an additional tool under my belt. let’s first load the library to get started. we will be dealing with the data frame, which is built into . since we’ve already loaded via , we can take a look at the data frame simply by typing its name. we will also be using the data set, also from . let’s take a look. basic syntax ============ let’s cut to the chase and take a look at a very simple example of a . things might look a bit confusing at first, but here is a brief rundown of the syntax: the obvious part is the declaration of data that we do inside the function. here, we simplify specify what data frame we are going to be using. then, we add s to the canvas. this is somewhat akin to calling and in python, where is like , , , or other variations, the is in a sense a set structure in r. as the name implies, maps various visualization attributes to the data. these attributes include basic things like and , as well as other aspects like , , or . for example, we might do something like in this case, the problem is that r only supports 6 different ticks or shapes by default, but we have 7 classes, making it impossible to render every data point. nonetheless, it demonstrates how we can toggle additional options within and . scoping we can also make use of scoping to reduce redundanceis. for example, consider the following graph declaration. this is cool, but notice that we are writing repated code for the mappings. instead, we can use global scoping under the function and streamline the code as follows: this is no rocket science: all that happened is that we moved the mapping arguments upward to , so that we no longer have to specify the mapping for each as we had done previously. this not only helps save time, but is also easier to maintain and read. we can also create subplots that separate out each plot for an axis or dimension of data. this can sound a bit abstract at first, and indeed i did have some trouble understanding what faceting meant when i first read the relevant portion, but it’s surprisingly simple. the executive summary is that facets can be considered as a row of plots extracted from a pair plot. enough talking, let’s take a look. as you can see, instead of having all data points in one graph, facetting allows us to divide up the data according to some axis, such as in this case. this might help us discover hidden trends that are not as obvious if the data were to be viewed in aggregate. we can also facet according to multiple axes instead of just one. the syntax is not so different from the previous example. the biggest difference is that instead of using , we use . here, we see the distribution of according to two axes, and . intuiting these facet graphs can get a bit more difficult as we start faceting around multiple axes, but simply think of it this way: instead of considering the data as a whole, we segment the data into certain groups according to their respective axeses or categories. fanciness is definitely not what defines a good visualization, but some degree of vibrance certainly helps portray information, if used correctly. let’s experiment with some colors. by specifying , we see that, as expected, the fill of each bar in the bar plot have been painted according to . this is good, but it doesn’t exactly add new information. we can perhaps get a bit more creative and add an additional dimension of information by specifying to be something other than , which is already handled by . for instance, now things look a bit more interesting. here, we not only see information on , but we also see the composition or distribution of level for each . this has certainly added a layer of information. we can also specify a positional arguments to modify the looks of the graph a bit further according to our tastes and needs. for example, makes the graphs such that it will fill the canvas. this information is informative in that it tells us that the higher the clarity of a dimaon, the more likely it is to be in a certain grade of cut. namely, the yellow clarity diamonds seems to belong to the most. there are other interesting options as well. for example, places overlapping objects next to each other. some other interesting options for scatter plots include . for the purposes of this notebook, however, we won’t go over every option there is: it suffices to demonstrate the role and functionality of the argument in r. the default coordinate system for is, as is the case with many other visualization packages, a cartesian coordinate. however, we can often apply transformations to alter the coordinate system. for example, consider the following bar plot: we applied some miscellaneous touches to the configuration of the graph, but the gist of it is what we have already seen: a bar plot with coloring. how can we make this graph more interesting? one way is to apply various transformations to the coordinates of the graph. for instance, let’s try flipping the axes: here, we used the function to literally flip the coordinates of the graph. this transformation can become particularly useful when the text labels of the data we are dealing with get very long. we can also transform the bar chart into a pie chart by moving to a polar coordinate from the cartesian. i personally find this visualization incredibly appealing. just a comment in passing. visualization syntax in this section, we’ve looked at various ways of creating visualizations and graphs. using this accumulated knowledge, we can now update the basic syntax of we’ve discussed in the previous section. recall our basic template: we can now add more bells and whistles to this formula: this contains a lot of information that we have dealt with so far, with the exception of the portion, which was dealt in the book but not in this notebook. i decided to leave that portion out because it appears to be a more intricate system that i might be interested as an intermediate user of . as of now, the default statistical transformations configured for each should suffice for most use cases. conclusion ========== is a powerful visualization library with many useful functions. although r’s vanilla plotting functions such as or , which we explored in this previous post are useful in their own right, offers more customizability and a wealth of functions that make it much more attractive for production. i hope to continue this series as i get through r for data science with my study buddies. i’ve realized that studying new programming languages, such as c and r, during quarantine period is a good way to stay motivated and productive during what could potentially be dull, grey hours. see you in the next post!
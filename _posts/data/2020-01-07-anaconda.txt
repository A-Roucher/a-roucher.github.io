as a novice who just started learning python just three months ago, i was clueless about what virtual environments were. all i knew was that anaconda was purportedly a good way to download and use python, in particular because it came with many scientific packages pre installed. i faintly remember reading somewhere that anaconda came with conda, a package manager, but i didn't really dig much into it because i was busy learning the python language to begin with. i wasn't interested in the complicated details i just wanted to learn how to use this language to start building and graphing and calculating. and because i had on idea about how to use anaconda or conda for that matter, i used to install packages left and right, using the pip installer through the command or through the conda installer, with some optional arguments and channel specifications that google and stack exchange search would tell me to do. for a package available on , i might have triggered a command something like this: little did i know back then that, my abusing these installation methods, my system root directory was being clogged up with so countless python packages and modules. the reason why i never bothered to dig into the intricacies of these installation options was that i never felt the need to: they almost always worked. after installing a package, i had no trouble importing it on pycharm or sublime. of course, there were some packages that simply didn't work, such as , but those were extremely rare, and i was always able to find an alternative package with similar functionality. admittedly, this in large part because the packages i use most often are extremely standard, such as , , and occasionally and , all of which are shipped with anaconda by default. problems started to arise only recently when i decided to starting learning r to expand my knowledge in the domain of statistical computing. after some quick research, i found that there were two ways of installing r on a local system. the most popular and easiest way was to download it straight from cran, the comprehensive r archive network. this was the course i followed first, and it was great until i realized that the better way to go would be to manage everything with conda through virtual environments. instead of a system wide installation of r, why not create a designated space for r within conda, and use jupyter notebooks from there? this question led me down a rabbit hole of stack exchange questions and medium posts. i summarize my findings here. installing r with conda could quite easily be achieved with a single command line. this command installs both r and the package, which includes approximately 80 most popular scientific packages for the r programming language. great! it took a few minutes for my laptop to complete the installation, but it eventually got through. now, i should be good to go, right? only, i noticed a few problems. first, when i opened a new terminal window, i realized that it took noticeably longer for the terminal to load. the bash shell seemed to look up multiple languages, such as , , and before fully loading, which i figured was a problem even to the uneducated eye, this meant that the system was unnecessarily clogged. it didn't take me long to realize that the cause of the problem was that all packages were being installed in the root directory of my system as mentioned earlier. this is not the recommended way of installing packages: in fact, the reason why we have package managers like conda is precisely to prevent users from installing everything in the root. conda allows users to create what are called "virtual environments." the simplest way to think about virtual environments that they are isolated universes where different packages live. having these isolated worlds is convenient because it means that users can install different versions of the same package. for instance, in a virtual environment called , we might install version 1.1; in , numpy versiosn 1.15. why might we want to do this? well, certain libraries that use as a dependency might require a specific version of . if we didn't have virtual environments, we would have to downgrade installed system wide on the root directory, and who knows what other compatability issues might pop up after the forced downgrade. virtual environments is essentially a very convenient way of managing where packages are installed while leaving the root directory clean and uncluttered. so the solution to my problem was simple: perform a conda reset to clean the root directory, which was then cluttered with both python and r modules. then, create virtual environments each for python and r and reinstall modules as necessary. through this, what i wanted to achieve was a clean system root environment, with all packages installed in specific virtual environments that i could toggle on or off depending on my workflow. resetting the conda root environment can simply achieved with a single line of command. on the terminal, type this will delete all pacakages installed in the root directory and revert the system back to where it was when we first installed anaconda. note that this includes the package we installed earlier. before running this command, i obtained a list of all libraries installed on the root just to see exactly what packages i had installed would be erased. to see the list of all available modules, type and the terminal will display the list of all packages installed in the current environment. after the resetting was complete, i ran a quick conda update command to make sure that all libraries werre up to date. now that the root directory has been unclogged, it's time to create virtual environments and reinstall packages onto our system! creating virtual environments is very easy. to create a python conda virtual environment, just type if you want to create a conda environment with all anaconda packages pre installed, add as an optional argument. notice that we can specify the python version on which the environment is going to run. this is another convenient perk of using virtual environments: we can use multiple python versions on the same machine simply by creating multiple virtual environments corresponding to each version. we can also create a virtual environment for r. to achieve this, simply type and now we are done! to make sure that all the virtual environments have been properly created, we can run a quick check command. in my case, i have created a total of 4 virtual environments, excluding the default root directory. to activate a virtual environment, we can use the command. for example, if i want to activate the virtual environment i created specifically for r, i would type and i would be good to go! objective achieved: clean the root directory and create a designated conda virtual environment for the r programming language. if you have been following along, you will realize that we still haven't figured out a way to use jupyter notebooks with r. in fact, if you have been following this post so far, you will realize that you only have one kernel available on jupyter notebooks, and that is python installed on the system root. to allow jupyter notebook to recognize each conda virtual environment, we need some tweaking to do: namely, installing kernel packages. let's say i want to use jupyter notebook with the virtual environment. first, let's activate the environment. next, let's install , which will allow jupyter notebook to recognize the conda virtual environment. then, we have to link the to jupyter notebooks with the following command: that's it! now, all we have to do is to repeat this process for the rest of the python conda virtual environments. for the virtual environment, a slightly different alteration has to be made to this procedure: instead of , we need to install through the following command. of course, we should execute this command after activating the r conda virtual environment. now, if we boot up jupyter notebook, we should be able to see that there is a kernel available for every conda virtual environment! now, we have an integrated system of virtual environments sall managed under conda, each conveniently accessible as kernels within jupyter notebooks! anaconda offers the option of installing rstudio through the anaconda distribution. however, much like the vast majority of r users i saw online, i do not recommend downloading rstudio through anaconda: the rstudio application available on anaconda is not up to date, nor is it supported by cran. instead, we can install rstudio through cran, but configure rstudio to locate the r profile in the anaconda directory instead of the standard directory that would be created had we installed the r language through cran. this sounds a needlessly complicated, so let's hash it out step by step. follow this link to install the rstudio application, which is the most widely used default ide for the r programming language. the good thing about rstudio is that it is free and open source, which is something that everybody likes. the installation should be very straight forward, so i'll jump straight into the problem. when you complete the installation and run the application, you will run into this error message. this message means that rstudio was unable to locate the directory where r is installed. the problem arises because we installed r through conda, not through cran. therefore, we have to manually specify the anaconda directory where r is installed for rstudio. in other words, we have to force rstudio to use a specific version of r installed on our system. this can be achieved by typing this bash command in the terminal: but how do we figure out where the anaconda r directory is located? first, let's activate the conda virtual environment where r is installed. next, we invoke the command to see where r is installed. great! now we know where the r profile is. all we have to do is use the command to configure the r directory for rstudio. in my case, this would look as follows: and now we are done! well, almost. if you try to open rstudio, it will still show you the same error. instead of opening the app via the launchpad, we have to open rstudio through the same terminal we used to configure rstudio. in other words, in the same terminal window, type now, rstudio should boot up and you should be able to use it without any problems! this approach works, but it's also inconvenient because we have to go through this process every time when we want to open up rstudio. not really productive, is it? the way to go about this problem is to create a shell alias. an alias is basically a personalized command on the terminal that we can invoke. using an alias, we can also chain multiple bash commands into a sweet, single line. pretty convenient, isn't it? it also suits our purpose because essentially the steps we have to take to launch r is type multiple commands on the shell interface before finally launching rstudio from the terminal. to create a system wide alias, we have to add an alias to our bash profile. first, let's locate the bash profile on our system in the root directory this is what shows up in my terminal. it tells me that there are 320 files in the root directory, one of which is the file that we have to edit to make our alias system wide and permanent. let's open the . a text editor will pop up, allowing us to view and edit the contents of the . after the last line of the profile, add the following lines. the alias i created is . essentially, what it does is that it chains multiple linux command lines into one convenient command that i can invoke in any terminal. it will automatically configure rstudio to look for the specific anacdona directory where r in installed in and open the rstudio application by browsing into the appropriate directory. in other words, instead of going through all the hassle, we can now simply type , and rstudio will fire up, ready for use! as someone who was unfamiliar with virtual environments, bash, and command lines, this little rabbit hole down the quest of using r with conda was an interesting experience. although all of what was dealt in this post was pretty basic and elementary tweaking, i am glad i was able to produce a working system all under conda. now that my r environment setup is complete, it's time to go back to studying the r programming language. i've only taken a cursory look at r, but the syntax seems interesting, and there are both parallels and differences i see in comparison to other langauges i know like python or java. hopefully i can get the hang of r and start using it for data analysis. catch you up in the next one! r: https://www.r project.org anaconda: https://anaconda.org conda: https://conda.io/en/ cran: http://cran.r project.org/mirrors.html this link: https://rstudio.com shell alias: https://www.geeksforgeeks.org/alias command in linux with examples/
these past few weeks, i've been powering through pytorch notebooks and tutorials, mostly because i enjoyed the pytorch api so much and found so many of it useful and intuitive. well, the problem was that i ended up writing something like ten notebooks without ever publishing them on this blog. so really, i'm going over some old notebooks i've coded out more than a month ago to finally make it live. that's enough excuses, let's get into the basics of pytorch modeling in this notebook with the cifar10 dataset and some basic cnns. the setup is pretty simple here. we import some modules and functions from pytorch, as well as to be able to show some basic training plots. one thing i have noticed is that a lot of people do something like which i personally don't really get, because you can easily just do if you ask me, i think the latter is more elegant and less cluttered . i don't think the two import statements are functionally different, but if i do figure out any differences, i will make sure to update future notebooks. one of the many nice things about pytorch is the clean, intuitive api. pytorch comes with good gpu support, and one of the main ways through which this can be done is by creating a object. device because i am running this notebook on my macbook pro, which obviously does not come with nvidia cuda enabled graphics cards, the device is set as the cpu. now, i can "move" tensors and models up to the gpu by doing something like and these statements would allow inference and training to occur within the gpu. and below are some constants i will be using in this notebook. namely, we will run training for a total of 4 epochs, with a batch size of 32 and a learning rate of 0.001. now that we have all the things we need, let's jump into some data preparation and modeling. another thing i love about pytorch is the sheer ease with which you can preprocess data. pytorch makes it incredibly easy to combine and stack multiple transforms to create custom transformations to be applied to the dataset. the easiest way to go about this is to use the method, which looks like this: here, we are applying to transformations: the first changes the dataset and casts it into pytorch tensors,, and the second one normalizes the dataset to have a mean of 0.5 and a standard deviation of also 0.5 across all three channels of rgb. how can we apply this transform? well, we can pass it to initialize the datasets as shown below: files already downloaded and verified files already downloaded and verified because i already have the cifar10 downloaded in the directory of my local, pytorch does not download the dataset again. we could go with the dataset as is, but we can use the class to further batch and shuffle the dataset, which we normally want 99 percent of the time. this is as simple as calling and passing in the dataset we want to load. if we loop through the , for instance, we can see that it is giving us a nice batch of 32 photos. note that the dimensions are in the form of . as for the labels, we get 32 values where each number corresponds to an image. torch.size torch.size as the last step, let's just make sure that we know what each of these labels correspond to. the is a tuple of strings that translate label indices to actual strings we can interpret. for example, if we see the label , we know that it denotes , which is . modeling in pytorch is the probably the part i love the most. tensorflow's sequential api is a great way to start, and pytorch also provides the same sort of way of building sequential models. however, once you try to build anything that's more complicated than that, i think pytorch's class based way of approaching modeling makes a lot more intuitive sense and provides more room for experimentation and customization. before getting into too much detail, below is a very simple cnn we will refer to as an example throughout this post. the first thing you will realize is that the model itself is a class that inherits from . this is a pattern you will see all the time with pytorch models. is a super class from which we can inherit to build anything from full fledged models to custom blocks or layers to be used in some other larger model. in the initialization function, we also define a number of layers that will be used in forward propagation. you might be wondering why these have to initialized in the initialization function, as opposed to the forward function itself. while i don't have a complete, technically cogent explanation to that question, intuitively, we can understand a model's layers as being components of the model itself. after all, the weights of these layers are adjusted with each iteration or epoch. in that sense, we want the layers to be attached to the model instance itself; hence the oop design of pytorch's model class. in this particular instance, we define a number of convolutional layers, a pooling layer, and two fully connected layers used for classification output. the declaration of the layers themselves are not too different from other frameworks, such as tensorflow. also, i've written out all the named arguments so that it is immediately clear what each argument is configuring. once we've declared all the necessary components in the initialization function, the next steps to actually churn out forward propagation results given some input. in pytorch, this is done by defining the function. as you can see above, we basically call on the layers we've declared in the initialization function via and pass in any parameters we want. since this is a very simple cnn, you will see that there is nothing exciting going on; we are simply getting the output of the previous layer and passing that as input into the next. after going through some convolutions and fully connected layers, we can return the result. there are one caveats worth mentioning here, which is the use of . there is a that i could have easily used, and indeed there is an entire discussion on the pytorch forum on the difference between the two. the bottom line is that they are pretty similar for our purposes. the most salient difference between the two is that the functional approach cannot be used when declaring a sequential model. however, since we are defining a custom forward function, this limitation does not apply. personally, i prefer the functional because it means that there is one less layer to declare in the initialization function. however, it's probably better to err on the side of the if you're not totally sure. now that we've designed and implemented a model, it's time to train it. this is the part where people might argue that tensorflow 2 or keras is superior to pytorch. in keras, you can simply call to train the model. however, in pytorch, this is not necessarily the case, unless you really want to imitate the keras api and define a function yourself. pytorch is more low level in that you need to define a custom training loop manually. however, i actually prefer this low levelness because it requires me to really think through what is happening in each iteration, namely what the dimension of each batch is, what the model expects to receive as input in the forward computation, and what loss function is appropriate given the output and label. let's see what all of this means. first, we begin by actually initializing an instance of the model, a loss function named , and an , which is adam in this case. a quick note of caution: if you dig into the pytorch documentation or look at other example classifiers, you will realize, like me, there are two loss functions you can typically use: and , or negative log likelihood loss. the difference between the former and latter is that, while the former applies a softmax function to the output before calculating the actual loss, the latter does not. in our case, since we simply output the raw logits instead of applying a softmax calculation, we need to use the former. let's return where we were. before we jump into training and defining the training loop, it's always a good idea to see if the output of the model is what you'd expect. in this case, we can simply define some random dummy input and see if the output is correct. torch.size now that we've verified the input and output dimensions, we can move onto defining the training loop. defining the training loop may seem difficult at first, especially if you're coming from a keras background, but actually a lot of it is boiler plate, and things are not as difficult as they may seem. first, we define a list to hold the loss values per iteration. we will be using this list for visualization later. the exciting part comes next. for each epoch, we load the images in the . note that the loader returns a tuple of images and labels, which we can unpack directly within the loop itself. we then move the two objects to , which would be necessary if we were running this one a cuda enabled computer. then, we calculate the loss by calling , the loss function, and append the loss to the list. note that we have to call since itself is a one by one pytorch tensor. epoch 1/4, batch 500/1563, loss: 1.2798 epoch 1/4, batch 1000/1563, loss: 1.1682 epoch 1/4, batch 1500/1563, loss: 1.3911 epoch 2/4, batch 500/1563, loss: 1.0510 epoch 2/4, batch 1000/1563, loss: 0.9175 epoch 2/4, batch 1500/1563, loss: 1.1130 epoch 3/4, batch 500/1563, loss: 0.9330 epoch 3/4, batch 1000/1563, loss: 0.6095 epoch 3/4, batch 1500/1563, loss: 0.7042 epoch 4/4, batch 500/1563, loss: 0.7850 epoch 4/4, batch 1000/1563, loss: 0.5785 epoch 4/4, batch 1500/1563, loss: 0.9072 then comes the important part where we perform backprop. the idea is that we would clear the previous gradient values, if any calculate the gradient for the current iteration apply the gradient to adjust weights the three steps correspond to each of the lines in the code above, starting from . as you might be able to guess from the name of the function, we zero the gradients to make sure that we aren't accumulating gradient values from one iteration to the next. calling corresponds to calculating the new gradient values, and performs the backprop. the last block of code is simply a convenient print function i've written to see the progress of training at certain intervals. as you can see, the loss seems to be decreasing for the most part, although it is jumpy at times. indeed, plotting makes it clear that the loss has been decreasing, though not entirely in a steady, monotonous fashion. in retrospect, we could have probably added a batch normalization layer to stabilize and expedite training. however, since this post is largely meant as an introduction to pytorch modeling, not model optimization or design, the example suffices. now we have finally reached the last step of the development cycle: testing and evaluating the model. this last step will also require us to write a custom loop as we receive batches of data from the object we've created above. the good news, however, is that the testing loop is not going to look too much different from the training loop; the only difference will be that we will not be backpropagating per each iteration. we will also be using to make sure that the model is in the evaluation mode, not its default training mode. this ensures that things like batch normalization and dropout work correctly. let's talk briefly about the details of this loop. here, the metric we're collecting is accuracy. first, we generally see how many correct predictions the model generates. then, we also see per class accuracy; that is, whether our model is good at predicting any particular class. this ensures that the model's performance is balanced throughout all labels. accuracy: 69.39% accuracy of plane: 75.6% accuracy of car: 81.3% accuracy of bird: 41.8% accuracy of cat: 62.6% accuracy of deer: 56.599999999999994% accuracy of dog: 63.9% accuracy of frog: 74.1% accuracy of horse: 75.8% accuracy of ship: 89.4% accuracy of truck: 72.8% and here is the result! an overall accuracy of 70 percent is definitely not impressive, and we certainly could have done better by building a deeper model, or by using more complex architectures. however, this isn't the worst performance considering the fact that we only had three convolutional layers. the more important takeaway from this tutorial is how to prepare data, build models, and train and evaluate them through a custom loop. from the tone and style of my writing, it is perhaps immediately clear to you that i am not officially a pytorch fanboy. yes, i will admit that i loved keras for its simplicity, but after having spent more time learning python and dl, i now much prefer the freedom provided by pytorch's reasonably abstract api. i hope this notebook provided you with a nice, simple introduction to pytorch. in the coming notebooks, we will take a deeper dive into implementing models with pytorch, starting from rnns all the way up to classic sota vision models like inceptionnet, resnet, and seq2seq models. i can definitely tell you that these are coming, because, as funny as this sounds, i already have all the notetbooks and code ready; i just have to annotate them. i hope you've enjoyed reading this post. catch you up in the next one!
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other day, my friend and I were talking about our mutual friend Jeremy. \"He's an oddball,\" my friend Sean remarked, to which I agreed. Out of nowhere, Jeremy had just told us that he would not be coming back to Korea for the next three years. \"He is just about the most random person I know.\" And both of us, being aspiring statistics majors, began wondering: is there a systematic way of measuirng randomness? It is from here that we went down the rabbit hole of Google and Wikipedia search. I ended up landing on entropy land, which is going to be the topic for today's post. Indeed, it's another random post on the topic of randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "\n",
    "To begin our conversation on randomness, let's take a look at how scientists measure the randomness of particles. If you are familiar with chemistry or molecular physics, you might be familiar with the concept of entropy, one of the core elements of thermodynamics and a topic that recurs throughout many subfields of natural sciences. Although I am no science major, one equation that I recall from high school chemistry class was the equation for calculating the spontaneity of some reaction using Gibbs Free energy, which went as follows:\n",
    "\n",
    "$$\\Delta G = \\Delta H - T \\Delta S$$\n",
    "\n",
    "where the term for entropy, denoted as $\\Delta S$ satisfies the condition that\n",
    "\n",
    "$$\\Delta S = k_B \\ln \\Omega$$\n",
    "\n",
    "We really don't have to get into the details of these equations here, but an intuition that we can glean from the concept of entropy in science is that the randomness of a particle is determined by the number of potential states that are possible for the given particle. In other words, if a gas particle that freely moves across space at ATP is going to be more random than a neaar-static water particle composing an ice cub. Then, it intuitively makes sense for us to say that the gas particle carries a larger amount of information than does the particle in a solid---after all, the gas particle would have a very wide probability distribution that encompasses various possible states and positionns, whereas the probability distribution for a particle composing a solid would have lesser variance, most likely concentrated at a point give its limited number of orientations. \n",
    "\n",
    "\n",
    "Entropy in science, deonted as $\\Delta S$, provides us with a valuable intuition on the topic of randomness and information. In fact, it is no coincidence that the notion of randomness in information theory, a subfield of math that we are going to be dipping out toes in, borrowed the term \"entropy\" \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...links...\n",
    "https://medium.com/activating-robotic-minds/demystifying-entropy-f2c3221e2550\n",
    "https://medium.com/udacity/shannon-entropy-information-gain-and-picking-balls-from-buckets-5810d35d54b4\n",
    "https://towardsdatascience.com/information-entropy-c037a90de58f\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
